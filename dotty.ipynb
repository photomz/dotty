{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/markuszhang/Downloads/deberta_v2_xxlarge_lora_mnli.bin'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.path.expanduser(\"~/Downloads/\")\n",
    "os.listdir(path)\n",
    "name = \"deberta_v2_xxlarge_lora_mnli.bin\"\n",
    "pth = path + name\n",
    "pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'deberta.encoder.layer.0.attention.self.query_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.0.attention.self.query_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.0.attention.self.value_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.0.attention.self.value_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.1.attention.self.query_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.1.attention.self.query_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.1.attention.self.value_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.1.attention.self.value_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.2.attention.self.query_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.2.attention.self.query_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.2.attention.self.value_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.2.attention.self.value_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.3.attention.self.query_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.3.attention.self.query_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.3.attention.self.value_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.3.attention.self.value_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.4.attention.self.query_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.4.attention.self.query_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.4.attention.self.value_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.4.attention.self.value_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.5.attention.self.query_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.5.attention.self.query_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.5.attention.self.value_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.5.attention.self.value_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.6.attention.self.query_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.6.attention.self.query_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.6.attention.self.value_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.6.attention.self.value_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.7.attention.self.query_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.7.attention.self.query_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.7.attention.self.value_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.7.attention.self.value_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.8.attention.self.query_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.8.attention.self.query_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.8.attention.self.value_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.8.attention.self.value_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.9.attention.self.query_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.9.attention.self.query_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.9.attention.self.value_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.9.attention.self.value_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.10.attention.self.query_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.10.attention.self.query_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.10.attention.self.value_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.10.attention.self.value_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.11.attention.self.query_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.11.attention.self.query_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.11.attention.self.value_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.11.attention.self.value_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.12.attention.self.query_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.12.attention.self.query_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.12.attention.self.value_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.12.attention.self.value_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.13.attention.self.query_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.13.attention.self.query_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.13.attention.self.value_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.13.attention.self.value_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.14.attention.self.query_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.14.attention.self.query_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.14.attention.self.value_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.14.attention.self.value_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.15.attention.self.query_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.15.attention.self.query_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.15.attention.self.value_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.15.attention.self.value_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.16.attention.self.query_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.16.attention.self.query_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.16.attention.self.value_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.16.attention.self.value_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.17.attention.self.query_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.17.attention.self.query_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.17.attention.self.value_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.17.attention.self.value_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.18.attention.self.query_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.18.attention.self.query_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.18.attention.self.value_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.18.attention.self.value_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.19.attention.self.query_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.19.attention.self.query_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.19.attention.self.value_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.19.attention.self.value_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.20.attention.self.query_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.20.attention.self.query_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.20.attention.self.value_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.20.attention.self.value_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.21.attention.self.query_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.21.attention.self.query_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.21.attention.self.value_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.21.attention.self.value_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.22.attention.self.query_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.22.attention.self.query_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.22.attention.self.value_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.22.attention.self.value_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.23.attention.self.query_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.23.attention.self.query_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.23.attention.self.value_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.23.attention.self.value_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.24.attention.self.query_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.24.attention.self.query_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.24.attention.self.value_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.24.attention.self.value_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.25.attention.self.query_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.25.attention.self.query_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.25.attention.self.value_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.25.attention.self.value_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.26.attention.self.query_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.26.attention.self.query_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.26.attention.self.value_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.26.attention.self.value_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.27.attention.self.query_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.27.attention.self.query_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.27.attention.self.value_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.27.attention.self.value_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.28.attention.self.query_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.28.attention.self.query_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.28.attention.self.value_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.28.attention.self.value_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.29.attention.self.query_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.29.attention.self.query_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.29.attention.self.value_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.29.attention.self.value_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.30.attention.self.query_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.30.attention.self.query_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.30.attention.self.value_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.30.attention.self.value_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.31.attention.self.query_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.31.attention.self.query_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.31.attention.self.value_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.31.attention.self.value_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.32.attention.self.query_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.32.attention.self.query_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.32.attention.self.value_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.32.attention.self.value_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.33.attention.self.query_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.33.attention.self.query_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.33.attention.self.value_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.33.attention.self.value_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.34.attention.self.query_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.34.attention.self.query_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.34.attention.self.value_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.34.attention.self.value_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.35.attention.self.query_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.35.attention.self.query_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.35.attention.self.value_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.35.attention.self.value_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.36.attention.self.query_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.36.attention.self.query_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.36.attention.self.value_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.36.attention.self.value_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.37.attention.self.query_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.37.attention.self.query_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.37.attention.self.value_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.37.attention.self.value_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.38.attention.self.query_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.38.attention.self.query_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.38.attention.self.value_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.38.attention.self.value_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.39.attention.self.query_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.39.attention.self.query_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.39.attention.self.value_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.39.attention.self.value_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.40.attention.self.query_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.40.attention.self.query_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.40.attention.self.value_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.40.attention.self.value_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.41.attention.self.query_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.41.attention.self.query_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.41.attention.self.value_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.41.attention.self.value_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.42.attention.self.query_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.42.attention.self.query_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.42.attention.self.value_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.42.attention.self.value_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.43.attention.self.query_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.43.attention.self.query_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.43.attention.self.value_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.43.attention.self.value_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.44.attention.self.query_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.44.attention.self.query_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.44.attention.self.value_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.44.attention.self.value_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.45.attention.self.query_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.45.attention.self.query_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.45.attention.self.value_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.45.attention.self.value_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.46.attention.self.query_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.46.attention.self.query_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.46.attention.self.value_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.46.attention.self.value_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.47.attention.self.query_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.47.attention.self.query_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'deberta.encoder.layer.47.attention.self.value_proj.lora_A': torch.Size([16, 1536]),\n",
       " 'deberta.encoder.layer.47.attention.self.value_proj.lora_B': torch.Size([1536, 16]),\n",
       " 'pooler.dense.weight': torch.Size([1536, 1536]),\n",
       " 'pooler.dense.bias': torch.Size([1536]),\n",
       " 'classifier.weight': torch.Size([3, 1536]),\n",
       " 'classifier.bias': torch.Size([3])}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assume: M1 Mac chip with MPS GPU\n",
    "# Load as memmap in cpu -> move to MPS GPU in float32 -> visualise in cpu\n",
    "state_dict = torch.load(pth, map_location=torch.device(\"cpu\"), mmap=True)\n",
    "{key: state_dict[key].shape for key in state_dict.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'deberta.encoder.layer.0.attention.self.query_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.0.attention.self.value_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.1.attention.self.query_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.1.attention.self.value_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.2.attention.self.query_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.2.attention.self.value_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.3.attention.self.query_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.3.attention.self.value_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.4.attention.self.query_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.4.attention.self.value_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.5.attention.self.query_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.5.attention.self.value_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.6.attention.self.query_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.6.attention.self.value_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.7.attention.self.query_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.7.attention.self.value_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.8.attention.self.query_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.8.attention.self.value_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.9.attention.self.query_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.9.attention.self.value_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.10.attention.self.query_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.10.attention.self.value_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.11.attention.self.query_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.11.attention.self.value_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.12.attention.self.query_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.12.attention.self.value_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.13.attention.self.query_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.13.attention.self.value_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.14.attention.self.query_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.14.attention.self.value_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.15.attention.self.query_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.15.attention.self.value_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.16.attention.self.query_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.16.attention.self.value_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.17.attention.self.query_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.17.attention.self.value_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.18.attention.self.query_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.18.attention.self.value_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.19.attention.self.query_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.19.attention.self.value_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.20.attention.self.query_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.20.attention.self.value_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.21.attention.self.query_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.21.attention.self.value_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.22.attention.self.query_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.22.attention.self.value_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.23.attention.self.query_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.23.attention.self.value_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.24.attention.self.query_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.24.attention.self.value_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.25.attention.self.query_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.25.attention.self.value_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.26.attention.self.query_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.26.attention.self.value_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.27.attention.self.query_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.27.attention.self.value_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.28.attention.self.query_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.28.attention.self.value_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.29.attention.self.query_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.29.attention.self.value_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.30.attention.self.query_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.30.attention.self.value_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.31.attention.self.query_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.31.attention.self.value_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.32.attention.self.query_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.32.attention.self.value_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.33.attention.self.query_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.33.attention.self.value_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.34.attention.self.query_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.34.attention.self.value_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.35.attention.self.query_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.35.attention.self.value_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.36.attention.self.query_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.36.attention.self.value_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.37.attention.self.query_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.37.attention.self.value_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.38.attention.self.query_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.38.attention.self.value_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.39.attention.self.query_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.39.attention.self.value_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.40.attention.self.query_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.40.attention.self.value_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.41.attention.self.query_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.41.attention.self.value_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.42.attention.self.query_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.42.attention.self.value_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.43.attention.self.query_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.43.attention.self.value_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.44.attention.self.query_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.44.attention.self.value_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.45.attention.self.query_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.45.attention.self.value_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.46.attention.self.query_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.46.attention.self.value_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.47.attention.self.query_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])],\n",
       " 'deberta.encoder.layer.47.attention.self.value_proj': [torch.Size([16, 1536]),\n",
       "  torch.Size([1536, 16])]}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_states = {}  # To store grouped A and B tensors\n",
    "\n",
    "for key, value in state_dict.items():\n",
    "    if \"lora\" in key:\n",
    "        lora_key = key.replace(\".lora_A\", \"\").replace(\n",
    "            \".lora_B\", \"\"\n",
    "        )  # Remove 'lora_A' or 'lora_B' suffix\n",
    "        if lora_key not in lora_states:\n",
    "            lora_states[lora_key] = [None, None]\n",
    "        if key.endswith(\".lora_A\"):\n",
    "            lora_states[lora_key][0] = value\n",
    "        elif key.endswith(\".lora_B\"):\n",
    "            lora_states[lora_key][1] = value\n",
    "            \n",
    "example_key = list(lora_states.keys())[0]\n",
    "{key: [value[0].shape, value[1].shape] for key, value in lora_states.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1536]) torch.Size([1536, 16])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 16]), torch.Size([1536, 1536]))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_pair = lora_states[example_key]\n",
    "a,b = lora_pair[0], lora_pair[1]\n",
    "print(a.shape, b.shape)\n",
    "\n",
    "# LoRa paper states BAx (page 4) -> b @ a\n",
    "(a @ b).shape, (b @ a).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'deberta.encoder.layer.0.attention.self.query_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.0.attention.self.value_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.1.attention.self.query_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.1.attention.self.value_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.2.attention.self.query_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.2.attention.self.value_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.3.attention.self.query_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.3.attention.self.value_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.4.attention.self.query_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.4.attention.self.value_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.5.attention.self.query_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.5.attention.self.value_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.6.attention.self.query_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.6.attention.self.value_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.7.attention.self.query_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.7.attention.self.value_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.8.attention.self.query_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.8.attention.self.value_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.9.attention.self.query_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.9.attention.self.value_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.10.attention.self.query_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.10.attention.self.value_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.11.attention.self.query_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.11.attention.self.value_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.12.attention.self.query_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.12.attention.self.value_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.13.attention.self.query_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.13.attention.self.value_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.14.attention.self.query_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.14.attention.self.value_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.15.attention.self.query_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.15.attention.self.value_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.16.attention.self.query_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.16.attention.self.value_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.17.attention.self.query_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.17.attention.self.value_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.18.attention.self.query_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.18.attention.self.value_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.19.attention.self.query_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.19.attention.self.value_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.20.attention.self.query_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.20.attention.self.value_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.21.attention.self.query_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.21.attention.self.value_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.22.attention.self.query_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.22.attention.self.value_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.23.attention.self.query_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.23.attention.self.value_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.24.attention.self.query_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.24.attention.self.value_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.25.attention.self.query_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.25.attention.self.value_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.26.attention.self.query_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.26.attention.self.value_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.27.attention.self.query_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.27.attention.self.value_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.28.attention.self.query_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.28.attention.self.value_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.29.attention.self.query_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.29.attention.self.value_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.30.attention.self.query_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.30.attention.self.value_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.31.attention.self.query_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.31.attention.self.value_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.32.attention.self.query_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.32.attention.self.value_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.33.attention.self.query_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.33.attention.self.value_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.34.attention.self.query_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.34.attention.self.value_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.35.attention.self.query_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.35.attention.self.value_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.36.attention.self.query_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.36.attention.self.value_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.37.attention.self.query_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.37.attention.self.value_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.38.attention.self.query_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.38.attention.self.value_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.39.attention.self.query_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.39.attention.self.value_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.40.attention.self.query_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.40.attention.self.value_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.41.attention.self.query_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.41.attention.self.value_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.42.attention.self.query_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.42.attention.self.value_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.43.attention.self.query_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.43.attention.self.value_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.44.attention.self.query_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.44.attention.self.value_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.45.attention.self.query_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.45.attention.self.value_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.46.attention.self.query_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.46.attention.self.value_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.47.attention.self.query_proj': torch.Size([1536, 1536]),\n",
       " 'deberta.encoder.layer.47.attention.self.value_proj': torch.Size([1536, 1536])}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Project matmul of B @ A to W, over every lora state pair dict\n",
    "delta_W_proj = {}\n",
    "for key, value in lora_states.items():\n",
    "\t\ta, b = value[0], value[1]\n",
    "\t\tdelta_W_proj[key] = b @ a\n",
    "{key: t.shape for key, t in delta_W_proj.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def angles_in_unit_vectors_of_matrix(matrix: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Find the angles between all the unit (column) vectors of a matrix.\n",
    "\n",
    "    Args:\n",
    "        matrix (torch.Tensor): Matrix of shape (N, M)\n",
    "\n",
    "    Returns:a\n",
    "        torch.Tensor: Angles in radians of shape (M, M)\n",
    "    \"\"\"\n",
    "    # Normalize columns to ensure they are unit vectors\n",
    "    normalized_matrix = matrix / matrix.norm(dim=0)\n",
    "\n",
    "    # Compute the dot product between all pairs of columns\n",
    "    dot_products = torch.matmul(normalized_matrix.t(), normalized_matrix)\n",
    "\n",
    "    # Ensure dot products are within [-1, 1] due to potential numerical issues\n",
    "    dot_products = torch.clamp(dot_products, min=-1.0, max=1.0)\n",
    "\n",
    "    # Compute the angles between columns using the arccosine function\n",
    "    angles = torch.acos(dot_products)\n",
    "\n",
    "    return angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "MPS = {'device': 'mps', 'dtype': torch.float32}\n",
    "CPU = {'device': 'cpu', 'dtype': torch.float16}\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.4527e-04, 2.2724e+00, 1.0722e+00,  ..., 1.5488e+00, 1.4152e+00,\n",
       "         1.4222e+00],\n",
       "        [2.2724e+00, 4.8828e-04, 2.5507e+00,  ..., 1.8642e+00, 1.4999e+00,\n",
       "         2.2385e+00],\n",
       "        [1.0722e+00, 2.5507e+00, 0.0000e+00,  ..., 9.6168e-01, 1.6644e+00,\n",
       "         1.1384e+00],\n",
       "        ...,\n",
       "        [1.5488e+00, 1.8642e+00, 9.6168e-01,  ..., 9.1349e-04, 1.5169e+00,\n",
       "         1.6161e+00],\n",
       "        [1.4152e+00, 1.4999e+00, 1.6644e+00,  ..., 1.5169e+00, 1.4236e-03,\n",
       "         2.1971e+00],\n",
       "        [1.4222e+00, 2.2385e+00, 1.1384e+00,  ..., 1.6161e+00, 2.1971e+00,\n",
       "         1.1451e-03]], device='mps:0')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "angles = angles_in_unit_vectors_of_matrix(delta_W_proj[example_key].to(**MPS))\n",
    "angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upper_triangle(symmetric_matrix):\n",
    "    \"\"\"\n",
    "    Extracts the upper triangle of a symmetric matrix (including the diagonal)\n",
    "    and returns a flat vector without the masked zeros.\n",
    "\n",
    "    Args:\n",
    "        symmetric_matrix (torch.Tensor): The symmetric matrix from which the upper\n",
    "            triangle (including the diagonal) will be extracted.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: A 1D tensor containing the upper triangle elements (including\n",
    "            the diagonal) without the masked zeros.\n",
    "    \"\"\"\n",
    "    # Use torch.triu to extract the upper triangle (including the diagonal)\n",
    "    upper_triangle = torch.triu(symmetric_matrix)\n",
    "\n",
    "    # Convert the upper triangle to a flat vector without masked zeros\n",
    "    flat_vector = upper_triangle[upper_triangle != 0]\n",
    "\n",
    "    return flat_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deberta.encoder.layer.0.attention.self.query_proj torch.Size([1536, 1536]) torch.Size([1179651])\n",
      "deberta.encoder.layer.0.attention.self.value_proj torch.Size([1536, 1536]) torch.Size([1179638])\n",
      "deberta.encoder.layer.1.attention.self.query_proj torch.Size([1536, 1536]) torch.Size([1179648])\n",
      "deberta.encoder.layer.1.attention.self.value_proj torch.Size([1536, 1536]) torch.Size([1179640])\n",
      "deberta.encoder.layer.2.attention.self.query_proj torch.Size([1536, 1536]) torch.Size([1179648])\n",
      "deberta.encoder.layer.2.attention.self.value_proj torch.Size([1536, 1536]) torch.Size([1179670])\n",
      "deberta.encoder.layer.3.attention.self.query_proj torch.Size([1536, 1536]) torch.Size([1179672])\n",
      "deberta.encoder.layer.3.attention.self.value_proj torch.Size([1536, 1536]) torch.Size([1179662])\n",
      "deberta.encoder.layer.4.attention.self.query_proj torch.Size([1536, 1536]) torch.Size([1179616])\n",
      "deberta.encoder.layer.4.attention.self.value_proj torch.Size([1536, 1536]) torch.Size([1179658])\n",
      "deberta.encoder.layer.5.attention.self.query_proj torch.Size([1536, 1536]) torch.Size([1179625])\n",
      "deberta.encoder.layer.5.attention.self.value_proj torch.Size([1536, 1536]) torch.Size([1179645])\n",
      "deberta.encoder.layer.6.attention.self.query_proj torch.Size([1536, 1536]) torch.Size([1179642])\n",
      "deberta.encoder.layer.6.attention.self.value_proj torch.Size([1536, 1536]) torch.Size([1179627])\n",
      "deberta.encoder.layer.7.attention.self.query_proj torch.Size([1536, 1536]) torch.Size([1179685])\n",
      "deberta.encoder.layer.7.attention.self.value_proj torch.Size([1536, 1536]) torch.Size([1179601])\n",
      "deberta.encoder.layer.8.attention.self.query_proj torch.Size([1536, 1536]) torch.Size([1179631])\n",
      "deberta.encoder.layer.8.attention.self.value_proj torch.Size([1536, 1536]) torch.Size([1179636])\n",
      "deberta.encoder.layer.9.attention.self.query_proj torch.Size([1536, 1536]) torch.Size([1179631])\n",
      "deberta.encoder.layer.9.attention.self.value_proj torch.Size([1536, 1536]) torch.Size([1179665])\n",
      "deberta.encoder.layer.10.attention.self.query_proj torch.Size([1536, 1536]) torch.Size([1179667])\n",
      "deberta.encoder.layer.10.attention.self.value_proj torch.Size([1536, 1536]) torch.Size([1179630])\n",
      "deberta.encoder.layer.11.attention.self.query_proj torch.Size([1536, 1536]) torch.Size([1179668])\n",
      "deberta.encoder.layer.11.attention.self.value_proj torch.Size([1536, 1536]) torch.Size([1179649])\n",
      "deberta.encoder.layer.12.attention.self.query_proj torch.Size([1536, 1536]) torch.Size([1179614])\n",
      "deberta.encoder.layer.12.attention.self.value_proj torch.Size([1536, 1536]) torch.Size([1179654])\n",
      "deberta.encoder.layer.13.attention.self.query_proj torch.Size([1536, 1536]) torch.Size([1179683])\n",
      "deberta.encoder.layer.13.attention.self.value_proj torch.Size([1536, 1536]) torch.Size([1179660])\n",
      "deberta.encoder.layer.14.attention.self.query_proj torch.Size([1536, 1536]) torch.Size([1179649])\n",
      "deberta.encoder.layer.14.attention.self.value_proj torch.Size([1536, 1536]) torch.Size([1179656])\n",
      "deberta.encoder.layer.15.attention.self.query_proj torch.Size([1536, 1536]) torch.Size([1179662])\n",
      "deberta.encoder.layer.15.attention.self.value_proj torch.Size([1536, 1536]) torch.Size([1179660])\n",
      "deberta.encoder.layer.16.attention.self.query_proj torch.Size([1536, 1536]) torch.Size([1179660])\n",
      "deberta.encoder.layer.16.attention.self.value_proj torch.Size([1536, 1536]) torch.Size([1179633])\n",
      "deberta.encoder.layer.17.attention.self.query_proj torch.Size([1536, 1536]) torch.Size([1179633])\n",
      "deberta.encoder.layer.17.attention.self.value_proj torch.Size([1536, 1536]) torch.Size([1179650])\n",
      "deberta.encoder.layer.18.attention.self.query_proj torch.Size([1536, 1536]) torch.Size([1179647])\n",
      "deberta.encoder.layer.18.attention.self.value_proj torch.Size([1536, 1536]) torch.Size([1179603])\n",
      "deberta.encoder.layer.19.attention.self.query_proj torch.Size([1536, 1536]) torch.Size([1179626])\n",
      "deberta.encoder.layer.19.attention.self.value_proj torch.Size([1536, 1536]) torch.Size([1179669])\n",
      "deberta.encoder.layer.20.attention.self.query_proj torch.Size([1536, 1536]) torch.Size([1179652])\n",
      "deberta.encoder.layer.20.attention.self.value_proj torch.Size([1536, 1536]) torch.Size([1179635])\n",
      "deberta.encoder.layer.21.attention.self.query_proj torch.Size([1536, 1536]) torch.Size([1179677])\n",
      "deberta.encoder.layer.21.attention.self.value_proj torch.Size([1536, 1536]) torch.Size([1179636])\n",
      "deberta.encoder.layer.22.attention.self.query_proj torch.Size([1536, 1536]) torch.Size([1179647])\n",
      "deberta.encoder.layer.22.attention.self.value_proj torch.Size([1536, 1536]) torch.Size([1179647])\n",
      "deberta.encoder.layer.23.attention.self.query_proj torch.Size([1536, 1536]) torch.Size([1179618])\n",
      "deberta.encoder.layer.23.attention.self.value_proj torch.Size([1536, 1536]) torch.Size([1179657])\n",
      "deberta.encoder.layer.24.attention.self.query_proj torch.Size([1536, 1536]) torch.Size([1179649])\n",
      "deberta.encoder.layer.24.attention.self.value_proj torch.Size([1536, 1536]) torch.Size([1179641])\n",
      "deberta.encoder.layer.25.attention.self.query_proj torch.Size([1536, 1536]) torch.Size([1179640])\n",
      "deberta.encoder.layer.25.attention.self.value_proj torch.Size([1536, 1536]) torch.Size([1179658])\n",
      "deberta.encoder.layer.26.attention.self.query_proj torch.Size([1536, 1536]) torch.Size([1179626])\n",
      "deberta.encoder.layer.26.attention.self.value_proj torch.Size([1536, 1536]) torch.Size([1179650])\n",
      "deberta.encoder.layer.27.attention.self.query_proj torch.Size([1536, 1536]) torch.Size([1179664])\n",
      "deberta.encoder.layer.27.attention.self.value_proj torch.Size([1536, 1536]) torch.Size([1179627])\n",
      "deberta.encoder.layer.28.attention.self.query_proj torch.Size([1536, 1536]) torch.Size([1179659])\n",
      "deberta.encoder.layer.28.attention.self.value_proj torch.Size([1536, 1536]) torch.Size([1179638])\n",
      "deberta.encoder.layer.29.attention.self.query_proj torch.Size([1536, 1536]) torch.Size([1179639])\n",
      "deberta.encoder.layer.29.attention.self.value_proj torch.Size([1536, 1536]) torch.Size([1179639])\n",
      "deberta.encoder.layer.30.attention.self.query_proj torch.Size([1536, 1536]) torch.Size([1179620])\n",
      "deberta.encoder.layer.30.attention.self.value_proj torch.Size([1536, 1536]) torch.Size([1179643])\n",
      "deberta.encoder.layer.31.attention.self.query_proj torch.Size([1536, 1536]) torch.Size([1179646])\n",
      "deberta.encoder.layer.31.attention.self.value_proj torch.Size([1536, 1536]) torch.Size([1179647])\n",
      "deberta.encoder.layer.32.attention.self.query_proj torch.Size([1536, 1536]) torch.Size([1179600])\n",
      "deberta.encoder.layer.32.attention.self.value_proj torch.Size([1536, 1536]) torch.Size([1179642])\n",
      "deberta.encoder.layer.33.attention.self.query_proj torch.Size([1536, 1536]) torch.Size([1179577])\n",
      "deberta.encoder.layer.33.attention.self.value_proj torch.Size([1536, 1536]) torch.Size([1179662])\n",
      "deberta.encoder.layer.34.attention.self.query_proj torch.Size([1536, 1536]) torch.Size([1179670])\n",
      "deberta.encoder.layer.34.attention.self.value_proj torch.Size([1536, 1536]) torch.Size([1179651])\n",
      "deberta.encoder.layer.35.attention.self.query_proj torch.Size([1536, 1536]) torch.Size([1179644])\n",
      "deberta.encoder.layer.35.attention.self.value_proj torch.Size([1536, 1536]) torch.Size([1179667])\n",
      "deberta.encoder.layer.36.attention.self.query_proj torch.Size([1536, 1536]) torch.Size([1179611])\n",
      "deberta.encoder.layer.36.attention.self.value_proj torch.Size([1536, 1536]) torch.Size([1179666])\n",
      "deberta.encoder.layer.37.attention.self.query_proj torch.Size([1536, 1536]) torch.Size([1179669])\n",
      "deberta.encoder.layer.37.attention.self.value_proj torch.Size([1536, 1536]) torch.Size([1179648])\n",
      "deberta.encoder.layer.38.attention.self.query_proj torch.Size([1536, 1536]) torch.Size([1179658])\n",
      "deberta.encoder.layer.38.attention.self.value_proj torch.Size([1536, 1536]) torch.Size([1179666])\n",
      "deberta.encoder.layer.39.attention.self.query_proj torch.Size([1536, 1536]) torch.Size([1179636])\n",
      "deberta.encoder.layer.39.attention.self.value_proj torch.Size([1536, 1536]) torch.Size([1179701])\n",
      "deberta.encoder.layer.40.attention.self.query_proj torch.Size([1536, 1536]) torch.Size([1179647])\n",
      "deberta.encoder.layer.40.attention.self.value_proj torch.Size([1536, 1536]) torch.Size([1179621])\n",
      "deberta.encoder.layer.41.attention.self.query_proj torch.Size([1536, 1536]) torch.Size([1179631])\n",
      "deberta.encoder.layer.41.attention.self.value_proj torch.Size([1536, 1536]) torch.Size([1179642])\n",
      "deberta.encoder.layer.42.attention.self.query_proj torch.Size([1536, 1536]) torch.Size([1179620])\n",
      "deberta.encoder.layer.42.attention.self.value_proj torch.Size([1536, 1536]) torch.Size([1179602])\n",
      "deberta.encoder.layer.43.attention.self.query_proj torch.Size([1536, 1536]) torch.Size([1179641])\n",
      "deberta.encoder.layer.43.attention.self.value_proj torch.Size([1536, 1536]) torch.Size([1179640])\n",
      "deberta.encoder.layer.44.attention.self.query_proj torch.Size([1536, 1536]) torch.Size([1179635])\n",
      "deberta.encoder.layer.44.attention.self.value_proj torch.Size([1536, 1536]) torch.Size([1179614])\n",
      "deberta.encoder.layer.45.attention.self.query_proj torch.Size([1536, 1536]) torch.Size([1179636])\n",
      "deberta.encoder.layer.45.attention.self.value_proj torch.Size([1536, 1536]) torch.Size([1179628])\n",
      "deberta.encoder.layer.46.attention.self.query_proj torch.Size([1536, 1536]) torch.Size([1179646])\n",
      "deberta.encoder.layer.46.attention.self.value_proj torch.Size([1536, 1536]) torch.Size([1179648])\n",
      "deberta.encoder.layer.47.attention.self.query_proj torch.Size([1536, 1536]) torch.Size([1179628])\n",
      "deberta.encoder.layer.47.attention.self.value_proj torch.Size([1536, 1536]) torch.Size([1179640])\n"
     ]
    }
   ],
   "source": [
    "angledict = {}\n",
    "for k,W in delta_W_proj.items():\n",
    "    matrix = W.to(**MPS)\n",
    "    # Vectors and empty tensors don't get LoRa'd.\n",
    "    if len(matrix.shape) >= 2:\n",
    "        angles = upper_triangle(angles_in_unit_vectors_of_matrix(matrix))\n",
    "        angledict[k] = angles.to(**CPU)\n",
    "        print(k, matrix.shape, angles.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save angledict\n",
    "path = f\"out/angledict_deberta_mnli.pt\"\n",
    "if os.path.exists(path):\n",
    "\t\traise Exception(f\"You are overwriting an existing torch tensor at: {path}\")\n",
    "else:\n",
    "  \ttorch.save(angledict, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'out/angledict_00001.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/markuszhang/Code/py/dotty/dotty.ipynb Cell 13\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/markuszhang/Code/py/dotty/dotty.ipynb#X23sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m MPS \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mdevice\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mmps\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m: torch\u001b[39m.\u001b[39mfloat32}\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/markuszhang/Code/py/dotty/dotty.ipynb#X23sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m CPU \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mdevice\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m: torch\u001b[39m.\u001b[39mfloat16}\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/markuszhang/Code/py/dotty/dotty.ipynb#X23sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m angledict \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mload(path \u001b[39m+\u001b[39;49m \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mangledict_0000\u001b[39;49m\u001b[39m{\u001b[39;49;00msplit_num\u001b[39m}\u001b[39;49;00m\u001b[39m.pt\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/markuszhang/Code/py/dotty/dotty.ipynb#X23sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m angledict\u001b[39m.\u001b[39mkeys()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/site-packages/torch/serialization.py:986\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pickle_load_args\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    984\u001b[0m     pickle_load_args[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 986\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[1;32m    987\u001b[0m     \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    988\u001b[0m         \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    989\u001b[0m         \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    990\u001b[0m         \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    991\u001b[0m         orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/site-packages/torch/serialization.py:435\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    434\u001b[0m     \u001b[39mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 435\u001b[0m         \u001b[39mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[1;32m    436\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    437\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/site-packages/torch/serialization.py:416\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, mode):\n\u001b[0;32m--> 416\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mopen\u001b[39;49m(name, mode))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'out/angledict_00001.pt'"
     ]
    }
   ],
   "source": [
    "# Load from disk to clear, garbage collect, and save RAM for us poor peasants\n",
    "import torch\n",
    "\n",
    "path = \"out/\"\n",
    "split_num = 1\n",
    "MPS = {\"device\": \"mps\", \"dtype\": torch.float32}\n",
    "CPU = {\"device\": \"cpu\", \"dtype\": torch.float16}\n",
    "angledict = torch.load(path + f\"angledict_0000{split_num}.pt\")\n",
    "angledict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deberta.encoder.layer.0.attention.self.query_proj torch.Size([1179651])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.0.attention.self.value_proj torch.Size([1179638])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.1.attention.self.query_proj torch.Size([1179648])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.1.attention.self.value_proj torch.Size([1179640])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.2.attention.self.query_proj torch.Size([1179648])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.2.attention.self.value_proj torch.Size([1179670])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.3.attention.self.query_proj torch.Size([1179672])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.3.attention.self.value_proj torch.Size([1179662])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.4.attention.self.query_proj torch.Size([1179616])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.4.attention.self.value_proj torch.Size([1179658])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.5.attention.self.query_proj torch.Size([1179625])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.5.attention.self.value_proj torch.Size([1179645])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.6.attention.self.query_proj torch.Size([1179642])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.6.attention.self.value_proj torch.Size([1179627])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.7.attention.self.query_proj torch.Size([1179685])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.7.attention.self.value_proj torch.Size([1179601])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.8.attention.self.query_proj torch.Size([1179631])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.8.attention.self.value_proj torch.Size([1179636])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.9.attention.self.query_proj torch.Size([1179631])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.9.attention.self.value_proj torch.Size([1179665])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.10.attention.self.query_proj torch.Size([1179667])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.10.attention.self.value_proj torch.Size([1179630])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.11.attention.self.query_proj torch.Size([1179668])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.11.attention.self.value_proj torch.Size([1179649])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.12.attention.self.query_proj torch.Size([1179614])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.12.attention.self.value_proj torch.Size([1179654])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.13.attention.self.query_proj torch.Size([1179683])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.13.attention.self.value_proj torch.Size([1179660])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.14.attention.self.query_proj torch.Size([1179649])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.14.attention.self.value_proj torch.Size([1179656])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.15.attention.self.query_proj torch.Size([1179662])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.15.attention.self.value_proj torch.Size([1179660])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.16.attention.self.query_proj torch.Size([1179660])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.16.attention.self.value_proj torch.Size([1179633])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.17.attention.self.query_proj torch.Size([1179633])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.17.attention.self.value_proj torch.Size([1179650])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.18.attention.self.query_proj torch.Size([1179647])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.18.attention.self.value_proj torch.Size([1179603])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.19.attention.self.query_proj torch.Size([1179626])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.19.attention.self.value_proj torch.Size([1179669])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.20.attention.self.query_proj torch.Size([1179652])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.20.attention.self.value_proj torch.Size([1179635])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.21.attention.self.query_proj torch.Size([1179677])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.21.attention.self.value_proj torch.Size([1179636])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.22.attention.self.query_proj torch.Size([1179647])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.22.attention.self.value_proj torch.Size([1179647])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.23.attention.self.query_proj torch.Size([1179618])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.23.attention.self.value_proj torch.Size([1179657])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.24.attention.self.query_proj torch.Size([1179649])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.24.attention.self.value_proj torch.Size([1179641])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.25.attention.self.query_proj torch.Size([1179640])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.25.attention.self.value_proj torch.Size([1179658])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.26.attention.self.query_proj torch.Size([1179626])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.26.attention.self.value_proj torch.Size([1179650])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.27.attention.self.query_proj torch.Size([1179664])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.27.attention.self.value_proj torch.Size([1179627])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.28.attention.self.query_proj torch.Size([1179659])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.28.attention.self.value_proj torch.Size([1179638])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.29.attention.self.query_proj torch.Size([1179639])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.29.attention.self.value_proj torch.Size([1179639])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.30.attention.self.query_proj torch.Size([1179620])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.30.attention.self.value_proj torch.Size([1179643])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.31.attention.self.query_proj torch.Size([1179646])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.31.attention.self.value_proj torch.Size([1179647])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.32.attention.self.query_proj torch.Size([1179600])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.32.attention.self.value_proj torch.Size([1179642])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.33.attention.self.query_proj torch.Size([1179577])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.33.attention.self.value_proj torch.Size([1179662])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.34.attention.self.query_proj torch.Size([1179670])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.34.attention.self.value_proj torch.Size([1179651])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.35.attention.self.query_proj torch.Size([1179644])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.35.attention.self.value_proj torch.Size([1179667])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.36.attention.self.query_proj torch.Size([1179611])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.36.attention.self.value_proj torch.Size([1179666])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.37.attention.self.query_proj torch.Size([1179669])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.37.attention.self.value_proj torch.Size([1179648])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.38.attention.self.query_proj torch.Size([1179658])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.38.attention.self.value_proj torch.Size([1179666])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.39.attention.self.query_proj torch.Size([1179636])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.39.attention.self.value_proj torch.Size([1179701])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.40.attention.self.query_proj torch.Size([1179647])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.40.attention.self.value_proj torch.Size([1179621])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.41.attention.self.query_proj torch.Size([1179631])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.41.attention.self.value_proj torch.Size([1179642])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.42.attention.self.query_proj torch.Size([1179620])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.42.attention.self.value_proj torch.Size([1179602])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.43.attention.self.query_proj torch.Size([1179641])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.43.attention.self.value_proj torch.Size([1179640])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.44.attention.self.query_proj torch.Size([1179635])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.44.attention.self.value_proj torch.Size([1179614])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.45.attention.self.query_proj torch.Size([1179636])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.45.attention.self.value_proj torch.Size([1179628])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.46.attention.self.query_proj torch.Size([1179646])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.46.attention.self.value_proj torch.Size([1179648])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.47.attention.self.query_proj torch.Size([1179628])\n",
      "--  torch.Size([1000])\n",
      "deberta.encoder.layer.47.attention.self.value_proj torch.Size([1179640])\n",
      "--  torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "dist = angledict[example_key].to(**MPS)\n",
    "dist[torch.multinomial(dist, 1000)]\n",
    "\n",
    "# For each layer, sample 1000 from multinomial\n",
    "sampled_angles = {}\n",
    "for k in angledict:\n",
    "    # Discard after 2**24 samples cause random sampler breaks\n",
    "    dist = angledict[k].to(**MPS)[: int(2**24)]\n",
    "    print(k, dist.shape)\n",
    "    sampled_angles[k] = dist[torch.multinomial(dist, 1000)].to(**CPU)\n",
    "    print(\"-- \", sampled_angles[k].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'deberta.encoder.layer.0.attention.self.query_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.0.attention.self.value_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.1.attention.self.query_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.1.attention.self.value_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.2.attention.self.query_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.2.attention.self.value_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.3.attention.self.query_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.3.attention.self.value_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.4.attention.self.query_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.4.attention.self.value_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.5.attention.self.query_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.5.attention.self.value_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.6.attention.self.query_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.6.attention.self.value_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.7.attention.self.query_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.7.attention.self.value_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.8.attention.self.query_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.8.attention.self.value_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.9.attention.self.query_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.9.attention.self.value_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.10.attention.self.query_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.10.attention.self.value_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.11.attention.self.query_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.11.attention.self.value_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.12.attention.self.query_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.12.attention.self.value_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.13.attention.self.query_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.13.attention.self.value_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.14.attention.self.query_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.14.attention.self.value_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.15.attention.self.query_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.15.attention.self.value_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.16.attention.self.query_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.16.attention.self.value_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.17.attention.self.query_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.17.attention.self.value_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.18.attention.self.query_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.18.attention.self.value_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.19.attention.self.query_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.19.attention.self.value_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.20.attention.self.query_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.20.attention.self.value_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.21.attention.self.query_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.21.attention.self.value_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.22.attention.self.query_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.22.attention.self.value_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.23.attention.self.query_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.23.attention.self.value_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.24.attention.self.query_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.24.attention.self.value_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.25.attention.self.query_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.25.attention.self.value_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.26.attention.self.query_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.26.attention.self.value_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.27.attention.self.query_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.27.attention.self.value_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.28.attention.self.query_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.28.attention.self.value_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.29.attention.self.query_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.29.attention.self.value_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.30.attention.self.query_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.30.attention.self.value_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.31.attention.self.query_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.31.attention.self.value_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.32.attention.self.query_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.32.attention.self.value_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.33.attention.self.query_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.33.attention.self.value_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.34.attention.self.query_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.34.attention.self.value_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.35.attention.self.query_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.35.attention.self.value_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.36.attention.self.query_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.36.attention.self.value_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.37.attention.self.query_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.37.attention.self.value_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.38.attention.self.query_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.38.attention.self.value_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.39.attention.self.query_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.39.attention.self.value_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.40.attention.self.query_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.40.attention.self.value_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.41.attention.self.query_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.41.attention.self.value_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.42.attention.self.query_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.42.attention.self.value_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.43.attention.self.query_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.43.attention.self.value_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.44.attention.self.query_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.44.attention.self.value_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.45.attention.self.query_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.45.attention.self.value_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.46.attention.self.query_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.46.attention.self.value_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.47.attention.self.query_proj': torch.Size([1000]),\n",
       " 'deberta.encoder.layer.47.attention.self.value_proj': torch.Size([1000])}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{key: sampled_angles[key].shape for key in sampled_angles.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming weights is the name of your dictionary\n",
    "# Can't plot 80M points. Sample 100K from distribution. Should tend to true dist.\n",
    "sampled_dist = torch.cat(list(sampled_angles.values())).numpy()\n",
    "\n",
    "plt.hist(sampled_dist, bins=100, log=True, color=\"cornflowerblue\", alpha=0.7)\n",
    "plt.title(\"Sampled Angles in Weight Matrices, Deberta LoRA SST2\")\n",
    "plt.xlabel(\"Angle between 2 unit vectors (Radians)\")\n",
    "plt.ylabel(\"Log Frequency\")\n",
    "\n",
    "# Draw a horizontal line at y=π/2\n",
    "plt.axvline(np.pi / 2, color=\"red\", linestyle=\"dashed\", linewidth=2, label=\"x=pi/2\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
