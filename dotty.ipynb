{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/markuszhang/Downloads/roberta_base_lora_mnli.bin'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.path.expanduser(\"~/Downloads/\")\n",
    "os.listdir(path)\n",
    "split_num = 1\n",
    "pth = path + \"roberta_base_lora_mnli.bin\"\n",
    "pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'roberta.encoder.layer.0.attention.self.query.lora_A': torch.Size([8, 768]),\n",
       " 'roberta.encoder.layer.0.attention.self.query.lora_B': torch.Size([768, 8]),\n",
       " 'roberta.encoder.layer.0.attention.self.value.lora_A': torch.Size([8, 768]),\n",
       " 'roberta.encoder.layer.0.attention.self.value.lora_B': torch.Size([768, 8]),\n",
       " 'roberta.encoder.layer.1.attention.self.query.lora_A': torch.Size([8, 768]),\n",
       " 'roberta.encoder.layer.1.attention.self.query.lora_B': torch.Size([768, 8]),\n",
       " 'roberta.encoder.layer.1.attention.self.value.lora_A': torch.Size([8, 768]),\n",
       " 'roberta.encoder.layer.1.attention.self.value.lora_B': torch.Size([768, 8]),\n",
       " 'roberta.encoder.layer.2.attention.self.query.lora_A': torch.Size([8, 768]),\n",
       " 'roberta.encoder.layer.2.attention.self.query.lora_B': torch.Size([768, 8]),\n",
       " 'roberta.encoder.layer.2.attention.self.value.lora_A': torch.Size([8, 768]),\n",
       " 'roberta.encoder.layer.2.attention.self.value.lora_B': torch.Size([768, 8]),\n",
       " 'roberta.encoder.layer.3.attention.self.query.lora_A': torch.Size([8, 768]),\n",
       " 'roberta.encoder.layer.3.attention.self.query.lora_B': torch.Size([768, 8]),\n",
       " 'roberta.encoder.layer.3.attention.self.value.lora_A': torch.Size([8, 768]),\n",
       " 'roberta.encoder.layer.3.attention.self.value.lora_B': torch.Size([768, 8]),\n",
       " 'roberta.encoder.layer.4.attention.self.query.lora_A': torch.Size([8, 768]),\n",
       " 'roberta.encoder.layer.4.attention.self.query.lora_B': torch.Size([768, 8]),\n",
       " 'roberta.encoder.layer.4.attention.self.value.lora_A': torch.Size([8, 768]),\n",
       " 'roberta.encoder.layer.4.attention.self.value.lora_B': torch.Size([768, 8]),\n",
       " 'roberta.encoder.layer.5.attention.self.query.lora_A': torch.Size([8, 768]),\n",
       " 'roberta.encoder.layer.5.attention.self.query.lora_B': torch.Size([768, 8]),\n",
       " 'roberta.encoder.layer.5.attention.self.value.lora_A': torch.Size([8, 768]),\n",
       " 'roberta.encoder.layer.5.attention.self.value.lora_B': torch.Size([768, 8]),\n",
       " 'roberta.encoder.layer.6.attention.self.query.lora_A': torch.Size([8, 768]),\n",
       " 'roberta.encoder.layer.6.attention.self.query.lora_B': torch.Size([768, 8]),\n",
       " 'roberta.encoder.layer.6.attention.self.value.lora_A': torch.Size([8, 768]),\n",
       " 'roberta.encoder.layer.6.attention.self.value.lora_B': torch.Size([768, 8]),\n",
       " 'roberta.encoder.layer.7.attention.self.query.lora_A': torch.Size([8, 768]),\n",
       " 'roberta.encoder.layer.7.attention.self.query.lora_B': torch.Size([768, 8]),\n",
       " 'roberta.encoder.layer.7.attention.self.value.lora_A': torch.Size([8, 768]),\n",
       " 'roberta.encoder.layer.7.attention.self.value.lora_B': torch.Size([768, 8]),\n",
       " 'roberta.encoder.layer.8.attention.self.query.lora_A': torch.Size([8, 768]),\n",
       " 'roberta.encoder.layer.8.attention.self.query.lora_B': torch.Size([768, 8]),\n",
       " 'roberta.encoder.layer.8.attention.self.value.lora_A': torch.Size([8, 768]),\n",
       " 'roberta.encoder.layer.8.attention.self.value.lora_B': torch.Size([768, 8]),\n",
       " 'roberta.encoder.layer.9.attention.self.query.lora_A': torch.Size([8, 768]),\n",
       " 'roberta.encoder.layer.9.attention.self.query.lora_B': torch.Size([768, 8]),\n",
       " 'roberta.encoder.layer.9.attention.self.value.lora_A': torch.Size([8, 768]),\n",
       " 'roberta.encoder.layer.9.attention.self.value.lora_B': torch.Size([768, 8]),\n",
       " 'roberta.encoder.layer.10.attention.self.query.lora_A': torch.Size([8, 768]),\n",
       " 'roberta.encoder.layer.10.attention.self.query.lora_B': torch.Size([768, 8]),\n",
       " 'roberta.encoder.layer.10.attention.self.value.lora_A': torch.Size([8, 768]),\n",
       " 'roberta.encoder.layer.10.attention.self.value.lora_B': torch.Size([768, 8]),\n",
       " 'roberta.encoder.layer.11.attention.self.query.lora_A': torch.Size([8, 768]),\n",
       " 'roberta.encoder.layer.11.attention.self.query.lora_B': torch.Size([768, 8]),\n",
       " 'roberta.encoder.layer.11.attention.self.value.lora_A': torch.Size([8, 768]),\n",
       " 'roberta.encoder.layer.11.attention.self.value.lora_B': torch.Size([768, 8]),\n",
       " 'classifier.dense.weight': torch.Size([768, 768]),\n",
       " 'classifier.dense.bias': torch.Size([768]),\n",
       " 'classifier.out_proj.weight': torch.Size([3, 768]),\n",
       " 'classifier.out_proj.bias': torch.Size([3])}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assume: M1 Mac chip with MPS GPU\n",
    "# Load as memmap in cpu -> move to MPS GPU in float32 -> visualise in cpu\n",
    "state_dict = torch.load(pth, map_location=torch.device(\"cpu\"), mmap=True)\n",
    "{key: state_dict[key].shape for key in state_dict.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'roberta.encoder.layer.0.attention.self.query': [torch.Size([8, 768]),\n",
       "  torch.Size([768, 8])],\n",
       " 'roberta.encoder.layer.0.attention.self.value': [torch.Size([8, 768]),\n",
       "  torch.Size([768, 8])],\n",
       " 'roberta.encoder.layer.1.attention.self.query': [torch.Size([8, 768]),\n",
       "  torch.Size([768, 8])],\n",
       " 'roberta.encoder.layer.1.attention.self.value': [torch.Size([8, 768]),\n",
       "  torch.Size([768, 8])],\n",
       " 'roberta.encoder.layer.2.attention.self.query': [torch.Size([8, 768]),\n",
       "  torch.Size([768, 8])],\n",
       " 'roberta.encoder.layer.2.attention.self.value': [torch.Size([8, 768]),\n",
       "  torch.Size([768, 8])],\n",
       " 'roberta.encoder.layer.3.attention.self.query': [torch.Size([8, 768]),\n",
       "  torch.Size([768, 8])],\n",
       " 'roberta.encoder.layer.3.attention.self.value': [torch.Size([8, 768]),\n",
       "  torch.Size([768, 8])],\n",
       " 'roberta.encoder.layer.4.attention.self.query': [torch.Size([8, 768]),\n",
       "  torch.Size([768, 8])],\n",
       " 'roberta.encoder.layer.4.attention.self.value': [torch.Size([8, 768]),\n",
       "  torch.Size([768, 8])],\n",
       " 'roberta.encoder.layer.5.attention.self.query': [torch.Size([8, 768]),\n",
       "  torch.Size([768, 8])],\n",
       " 'roberta.encoder.layer.5.attention.self.value': [torch.Size([8, 768]),\n",
       "  torch.Size([768, 8])],\n",
       " 'roberta.encoder.layer.6.attention.self.query': [torch.Size([8, 768]),\n",
       "  torch.Size([768, 8])],\n",
       " 'roberta.encoder.layer.6.attention.self.value': [torch.Size([8, 768]),\n",
       "  torch.Size([768, 8])],\n",
       " 'roberta.encoder.layer.7.attention.self.query': [torch.Size([8, 768]),\n",
       "  torch.Size([768, 8])],\n",
       " 'roberta.encoder.layer.7.attention.self.value': [torch.Size([8, 768]),\n",
       "  torch.Size([768, 8])],\n",
       " 'roberta.encoder.layer.8.attention.self.query': [torch.Size([8, 768]),\n",
       "  torch.Size([768, 8])],\n",
       " 'roberta.encoder.layer.8.attention.self.value': [torch.Size([8, 768]),\n",
       "  torch.Size([768, 8])],\n",
       " 'roberta.encoder.layer.9.attention.self.query': [torch.Size([8, 768]),\n",
       "  torch.Size([768, 8])],\n",
       " 'roberta.encoder.layer.9.attention.self.value': [torch.Size([8, 768]),\n",
       "  torch.Size([768, 8])],\n",
       " 'roberta.encoder.layer.10.attention.self.query': [torch.Size([8, 768]),\n",
       "  torch.Size([768, 8])],\n",
       " 'roberta.encoder.layer.10.attention.self.value': [torch.Size([8, 768]),\n",
       "  torch.Size([768, 8])],\n",
       " 'roberta.encoder.layer.11.attention.self.query': [torch.Size([8, 768]),\n",
       "  torch.Size([768, 8])],\n",
       " 'roberta.encoder.layer.11.attention.self.value': [torch.Size([8, 768]),\n",
       "  torch.Size([768, 8])]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_states = {}  # To store grouped A and B tensors\n",
    "\n",
    "for key, value in state_dict.items():\n",
    "    if \"lora\" in key:\n",
    "        lora_key = key.replace(\".lora_A\", \"\").replace(\n",
    "            \".lora_B\", \"\"\n",
    "        )  # Remove 'lora_A' or 'lora_B' suffix\n",
    "        if lora_key not in lora_states:\n",
    "            lora_states[lora_key] = [None, None]\n",
    "        if key.endswith(\".lora_A\"):\n",
    "            lora_states[lora_key][0] = value\n",
    "        elif key.endswith(\".lora_B\"):\n",
    "            lora_states[lora_key][1] = value\n",
    "{key: [value[0].shape, value[1].shape] for key, value in lora_states.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 768]) torch.Size([768, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 8]), torch.Size([768, 768]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_pair = lora_states[\"roberta.encoder.layer.0.attention.self.query\"]\n",
    "a,b = lora_pair[0], lora_pair[1]\n",
    "print(a.shape, b.shape)\n",
    "\n",
    "# LoRa paper states BAx (page 4) -> b @ a\n",
    "(a @ b).shape, (b @ a).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'roberta.encoder.layer.0.attention.self.query': torch.Size([768, 768]),\n",
       " 'roberta.encoder.layer.0.attention.self.value': torch.Size([768, 768]),\n",
       " 'roberta.encoder.layer.1.attention.self.query': torch.Size([768, 768]),\n",
       " 'roberta.encoder.layer.1.attention.self.value': torch.Size([768, 768]),\n",
       " 'roberta.encoder.layer.2.attention.self.query': torch.Size([768, 768]),\n",
       " 'roberta.encoder.layer.2.attention.self.value': torch.Size([768, 768]),\n",
       " 'roberta.encoder.layer.3.attention.self.query': torch.Size([768, 768]),\n",
       " 'roberta.encoder.layer.3.attention.self.value': torch.Size([768, 768]),\n",
       " 'roberta.encoder.layer.4.attention.self.query': torch.Size([768, 768]),\n",
       " 'roberta.encoder.layer.4.attention.self.value': torch.Size([768, 768]),\n",
       " 'roberta.encoder.layer.5.attention.self.query': torch.Size([768, 768]),\n",
       " 'roberta.encoder.layer.5.attention.self.value': torch.Size([768, 768]),\n",
       " 'roberta.encoder.layer.6.attention.self.query': torch.Size([768, 768]),\n",
       " 'roberta.encoder.layer.6.attention.self.value': torch.Size([768, 768]),\n",
       " 'roberta.encoder.layer.7.attention.self.query': torch.Size([768, 768]),\n",
       " 'roberta.encoder.layer.7.attention.self.value': torch.Size([768, 768]),\n",
       " 'roberta.encoder.layer.8.attention.self.query': torch.Size([768, 768]),\n",
       " 'roberta.encoder.layer.8.attention.self.value': torch.Size([768, 768]),\n",
       " 'roberta.encoder.layer.9.attention.self.query': torch.Size([768, 768]),\n",
       " 'roberta.encoder.layer.9.attention.self.value': torch.Size([768, 768]),\n",
       " 'roberta.encoder.layer.10.attention.self.query': torch.Size([768, 768]),\n",
       " 'roberta.encoder.layer.10.attention.self.value': torch.Size([768, 768]),\n",
       " 'roberta.encoder.layer.11.attention.self.query': torch.Size([768, 768]),\n",
       " 'roberta.encoder.layer.11.attention.self.value': torch.Size([768, 768])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Project matmul of B @ A to W, over every lora state pair dict\n",
    "delta_W_proj = {}\n",
    "for key, value in lora_states.items():\n",
    "\t\ta, b = value[0], value[1]\n",
    "\t\tdelta_W_proj[key] = b @ a\n",
    "{key: t.shape for key, t in delta_W_proj.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def angles_in_unit_vectors_of_matrix(matrix: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Find the angles between all the unit (column) vectors of a matrix.\n",
    "\n",
    "    Args:\n",
    "        matrix (torch.Tensor): Matrix of shape (N, M)\n",
    "\n",
    "    Returns:a\n",
    "        torch.Tensor: Angles in radians of shape (M, M)\n",
    "    \"\"\"\n",
    "    # Normalize columns to ensure they are unit vectors\n",
    "    normalized_matrix = matrix / matrix.norm(dim=0)\n",
    "\n",
    "    # Compute the dot product between all pairs of columns\n",
    "    dot_products = torch.matmul(normalized_matrix.t(), normalized_matrix)\n",
    "\n",
    "    # Ensure dot products are within [-1, 1] due to potential numerical issues\n",
    "    dot_products = torch.clamp(dot_products, min=-1.0, max=1.0)\n",
    "\n",
    "    # Compute the angles between columns using the arccosine function\n",
    "    angles = torch.acos(dot_products)\n",
    "\n",
    "    return angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MPS = {'device': 'mps', 'dtype': torch.float32}\n",
    "CPU = {'device': 'cpu', 'dtype': torch.float16}\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/markuszhang/.pyenv/versions/3.11.4/lib/python3.11/site-packages/torch/_tensor_str.py:137: UserWarning: MPS: nonzero op is supported natively starting from macOS 13.0. Falling back on CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/mps/operations/Indexing.mm:283.)\n",
      "  nonzero_finite_vals = torch.masked_select(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000e+00, 2.0451e+00, 1.5361e+00,  ..., 1.1952e+00, 1.3364e+00,\n",
       "         1.7809e+00],\n",
       "        [2.0451e+00, 1.0358e-03, 1.4534e+00,  ..., 2.4371e+00, 1.1605e+00,\n",
       "         1.2175e+00],\n",
       "        [1.5361e+00, 1.4534e+00, 3.4527e-04,  ..., 2.1219e+00, 7.5401e-01,\n",
       "         1.1036e+00],\n",
       "        ...,\n",
       "        [1.1952e+00, 2.4371e+00, 2.1219e+00,  ..., 0.0000e+00, 2.4260e+00,\n",
       "         2.4368e+00],\n",
       "        [1.3364e+00, 1.1605e+00, 7.5401e-01,  ..., 2.4260e+00, 5.9802e-04,\n",
       "         1.0312e+00],\n",
       "        [1.7809e+00, 1.2175e+00, 1.1036e+00,  ..., 2.4368e+00, 1.0312e+00,\n",
       "         1.0358e-03]], device='mps:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "angles = angles_in_unit_vectors_of_matrix(\n",
    "    delta_W_proj[\"roberta.encoder.layer.0.attention.self.query\"].to(**MPS)\n",
    ")\n",
    "angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upper_triangle(symmetric_matrix):\n",
    "    \"\"\"\n",
    "    Extracts the upper triangle of a symmetric matrix (including the diagonal)\n",
    "    and returns a flat vector without the masked zeros.\n",
    "\n",
    "    Args:\n",
    "        symmetric_matrix (torch.Tensor): The symmetric matrix from which the upper\n",
    "            triangle (including the diagonal) will be extracted.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: A 1D tensor containing the upper triangle elements (including\n",
    "            the diagonal) without the masked zeros.\n",
    "    \"\"\"\n",
    "    # Use torch.triu to extract the upper triangle (including the diagonal)\n",
    "    upper_triangle = torch.triu(symmetric_matrix)\n",
    "\n",
    "    # Convert the upper triangle to a flat vector without masked zeros\n",
    "    flat_vector = upper_triangle[upper_triangle != 0]\n",
    "\n",
    "    return flat_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roberta.encoder.layer.0.attention.self.query torch.Size([768, 768]) torch.Size([294889])\n",
      "roberta.encoder.layer.0.attention.self.value torch.Size([768, 768]) torch.Size([294904])\n",
      "roberta.encoder.layer.1.attention.self.query torch.Size([768, 768]) torch.Size([294895])\n",
      "roberta.encoder.layer.1.attention.self.value torch.Size([768, 768]) torch.Size([294898])\n",
      "roberta.encoder.layer.2.attention.self.query torch.Size([768, 768]) torch.Size([294887])\n",
      "roberta.encoder.layer.2.attention.self.value torch.Size([768, 768]) torch.Size([294897])\n",
      "roberta.encoder.layer.3.attention.self.query torch.Size([768, 768]) torch.Size([294909])\n",
      "roberta.encoder.layer.3.attention.self.value torch.Size([768, 768]) torch.Size([294921])\n",
      "roberta.encoder.layer.4.attention.self.query torch.Size([768, 768]) torch.Size([294913])\n",
      "roberta.encoder.layer.4.attention.self.value torch.Size([768, 768]) torch.Size([294890])\n",
      "roberta.encoder.layer.5.attention.self.query torch.Size([768, 768]) torch.Size([294890])\n",
      "roberta.encoder.layer.5.attention.self.value torch.Size([768, 768]) torch.Size([294909])\n",
      "roberta.encoder.layer.6.attention.self.query torch.Size([768, 768]) torch.Size([294868])\n",
      "roberta.encoder.layer.6.attention.self.value torch.Size([768, 768]) torch.Size([294920])\n",
      "roberta.encoder.layer.7.attention.self.query torch.Size([768, 768]) torch.Size([294880])\n",
      "roberta.encoder.layer.7.attention.self.value torch.Size([768, 768]) torch.Size([294900])\n",
      "roberta.encoder.layer.8.attention.self.query torch.Size([768, 768]) torch.Size([294918])\n",
      "roberta.encoder.layer.8.attention.self.value torch.Size([768, 768]) torch.Size([294912])\n",
      "roberta.encoder.layer.9.attention.self.query torch.Size([768, 768]) torch.Size([294896])\n",
      "roberta.encoder.layer.9.attention.self.value torch.Size([768, 768]) torch.Size([294882])\n",
      "roberta.encoder.layer.10.attention.self.query torch.Size([768, 768]) torch.Size([294905])\n",
      "roberta.encoder.layer.10.attention.self.value torch.Size([768, 768]) torch.Size([294909])\n",
      "roberta.encoder.layer.11.attention.self.query torch.Size([768, 768]) torch.Size([294905])\n",
      "roberta.encoder.layer.11.attention.self.value torch.Size([768, 768]) torch.Size([294883])\n"
     ]
    }
   ],
   "source": [
    "angledict = {}\n",
    "for k,W in delta_W_proj.items():\n",
    "    matrix = W.to(**MPS)\n",
    "    # Vectors and empty tensors don't get LoRa'd.\n",
    "    if len(matrix.shape) >= 2:\n",
    "        angles = upper_triangle(angles_in_unit_vectors_of_matrix(matrix))\n",
    "        angledict[k] = angles.to(**CPU)\n",
    "        print(k, matrix.shape, angles.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save angledict\n",
    "torch.save(angledict, f\"out/angledict_roberta.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['model.embed_tokens.weight', 'model.layers.0.self_attn.q_proj.weight', 'model.layers.0.self_attn.k_proj.weight', 'model.layers.0.self_attn.v_proj.weight', 'model.layers.0.self_attn.o_proj.weight', 'model.layers.0.mlp.gate_proj.weight', 'model.layers.0.mlp.down_proj.weight', 'model.layers.0.mlp.up_proj.weight', 'model.layers.1.self_attn.q_proj.weight', 'model.layers.1.self_attn.k_proj.weight', 'model.layers.1.self_attn.v_proj.weight', 'model.layers.1.self_attn.o_proj.weight', 'model.layers.1.mlp.gate_proj.weight', 'model.layers.1.mlp.down_proj.weight', 'model.layers.1.mlp.up_proj.weight', 'model.layers.2.self_attn.q_proj.weight', 'model.layers.2.self_attn.k_proj.weight', 'model.layers.2.self_attn.v_proj.weight', 'model.layers.2.self_attn.o_proj.weight', 'model.layers.2.mlp.gate_proj.weight', 'model.layers.2.mlp.down_proj.weight', 'model.layers.2.mlp.up_proj.weight', 'model.layers.3.self_attn.q_proj.weight', 'model.layers.3.self_attn.k_proj.weight', 'model.layers.3.self_attn.v_proj.weight', 'model.layers.3.self_attn.o_proj.weight', 'model.layers.3.mlp.gate_proj.weight', 'model.layers.3.mlp.down_proj.weight', 'model.layers.3.mlp.up_proj.weight', 'model.layers.4.self_attn.q_proj.weight', 'model.layers.4.self_attn.k_proj.weight', 'model.layers.4.self_attn.v_proj.weight', 'model.layers.4.self_attn.o_proj.weight', 'model.layers.4.mlp.gate_proj.weight', 'model.layers.4.mlp.down_proj.weight', 'model.layers.4.mlp.up_proj.weight', 'model.layers.5.self_attn.q_proj.weight', 'model.layers.5.self_attn.k_proj.weight', 'model.layers.5.self_attn.v_proj.weight', 'model.layers.5.self_attn.o_proj.weight', 'model.layers.5.mlp.gate_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.5.mlp.up_proj.weight', 'model.layers.6.self_attn.q_proj.weight', 'model.layers.6.self_attn.k_proj.weight', 'model.layers.6.self_attn.v_proj.weight', 'model.layers.6.self_attn.o_proj.weight', 'model.layers.6.mlp.gate_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.6.mlp.up_proj.weight', 'model.layers.7.self_attn.q_proj.weight', 'model.layers.7.self_attn.k_proj.weight', 'model.layers.7.self_attn.v_proj.weight', 'model.layers.7.self_attn.o_proj.weight', 'model.layers.7.mlp.gate_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.7.mlp.up_proj.weight', 'model.layers.8.self_attn.q_proj.weight', 'model.layers.8.self_attn.k_proj.weight', 'model.layers.8.self_attn.v_proj.weight', 'model.layers.8.self_attn.o_proj.weight', 'model.layers.8.mlp.gate_proj.weight', 'model.layers.8.mlp.down_proj.weight', 'model.layers.8.mlp.up_proj.weight', 'model.layers.9.self_attn.q_proj.weight', 'model.layers.9.self_attn.k_proj.weight', 'model.layers.9.self_attn.v_proj.weight', 'model.layers.9.self_attn.o_proj.weight', 'model.layers.9.mlp.gate_proj.weight', 'model.layers.9.mlp.down_proj.weight', 'model.layers.9.mlp.up_proj.weight', 'model.layers.10.self_attn.q_proj.weight', 'model.layers.10.self_attn.k_proj.weight', 'model.layers.10.self_attn.v_proj.weight', 'model.layers.10.self_attn.o_proj.weight', 'model.layers.10.mlp.gate_proj.weight', 'model.layers.10.mlp.down_proj.weight', 'model.layers.10.mlp.up_proj.weight', 'model.layers.11.self_attn.q_proj.weight', 'model.layers.11.self_attn.k_proj.weight', 'model.layers.11.self_attn.v_proj.weight', 'model.layers.11.self_attn.o_proj.weight', 'model.layers.11.mlp.gate_proj.weight'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load from disk to clear, garbage collect, and save RAM for us poor peasants\n",
    "import torch\n",
    "\n",
    "path = \"out/\"\n",
    "split_num = 1\n",
    "MPS = {\"device\": \"mps\", \"dtype\": torch.float32}\n",
    "CPU = {\"device\": \"cpu\", \"dtype\": torch.float16}\n",
    "angledict = torch.load(path + f\"angledict_0000{split_num}.pt\")\n",
    "angledict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kq/mtjf6mbj4rv07rcz7sq40s6w0000gn/T/ipykernel_33315/169135902.py:2: UserWarning: torch.topk support for k>16 by MPS on MacOS 13+, please upgrade (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/mps/operations/Shape.mm:71.)\n",
      "  dist[torch.multinomial(dist, 1000)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roberta.encoder.layer.0.attention.self.query torch.Size([294889])\n",
      "--  torch.Size([1000])\n",
      "roberta.encoder.layer.0.attention.self.value torch.Size([294904])\n",
      "--  torch.Size([1000])\n",
      "roberta.encoder.layer.1.attention.self.query torch.Size([294895])\n",
      "--  torch.Size([1000])\n",
      "roberta.encoder.layer.1.attention.self.value torch.Size([294898])\n",
      "--  torch.Size([1000])\n",
      "roberta.encoder.layer.2.attention.self.query torch.Size([294887])\n",
      "--  torch.Size([1000])\n",
      "roberta.encoder.layer.2.attention.self.value torch.Size([294897])\n",
      "--  torch.Size([1000])\n",
      "roberta.encoder.layer.3.attention.self.query torch.Size([294909])\n",
      "--  torch.Size([1000])\n",
      "roberta.encoder.layer.3.attention.self.value torch.Size([294921])\n",
      "--  torch.Size([1000])\n",
      "roberta.encoder.layer.4.attention.self.query torch.Size([294913])\n",
      "--  torch.Size([1000])\n",
      "roberta.encoder.layer.4.attention.self.value torch.Size([294890])\n",
      "--  torch.Size([1000])\n",
      "roberta.encoder.layer.5.attention.self.query torch.Size([294890])\n",
      "--  torch.Size([1000])\n",
      "roberta.encoder.layer.5.attention.self.value torch.Size([294909])\n",
      "--  torch.Size([1000])\n",
      "roberta.encoder.layer.6.attention.self.query torch.Size([294868])\n",
      "--  torch.Size([1000])\n",
      "roberta.encoder.layer.6.attention.self.value torch.Size([294920])\n",
      "--  torch.Size([1000])\n",
      "roberta.encoder.layer.7.attention.self.query torch.Size([294880])\n",
      "--  torch.Size([1000])\n",
      "roberta.encoder.layer.7.attention.self.value torch.Size([294900])\n",
      "--  torch.Size([1000])\n",
      "roberta.encoder.layer.8.attention.self.query torch.Size([294918])\n",
      "--  torch.Size([1000])\n",
      "roberta.encoder.layer.8.attention.self.value torch.Size([294912])\n",
      "--  torch.Size([1000])\n",
      "roberta.encoder.layer.9.attention.self.query torch.Size([294896])\n",
      "--  torch.Size([1000])\n",
      "roberta.encoder.layer.9.attention.self.value torch.Size([294882])\n",
      "--  torch.Size([1000])\n",
      "roberta.encoder.layer.10.attention.self.query torch.Size([294905])\n",
      "--  torch.Size([1000])\n",
      "roberta.encoder.layer.10.attention.self.value torch.Size([294909])\n",
      "--  torch.Size([1000])\n",
      "roberta.encoder.layer.11.attention.self.query torch.Size([294905])\n",
      "--  torch.Size([1000])\n",
      "roberta.encoder.layer.11.attention.self.value torch.Size([294883])\n",
      "--  torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "dist = angledict[\"roberta.encoder.layer.0.attention.self.query\"].to(**MPS)\n",
    "dist[torch.multinomial(dist, 1000)]\n",
    "\n",
    "# For each layer, sample 1000 from multinomial\n",
    "sampled_angles = {}\n",
    "for k in angledict:\n",
    "    # Discard after 2**24 samples cause random sampler breaks\n",
    "    dist = angledict[k].to(**MPS)[: int(2**24)]\n",
    "    print(k, dist.shape)\n",
    "    sampled_angles[k] = dist[torch.multinomial(dist, 1000)].to(**CPU)\n",
    "    print(\"-- \", sampled_angles[k].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'roberta.encoder.layer.0.attention.self.query': torch.Size([1000]),\n",
       " 'roberta.encoder.layer.0.attention.self.value': torch.Size([1000]),\n",
       " 'roberta.encoder.layer.1.attention.self.query': torch.Size([1000]),\n",
       " 'roberta.encoder.layer.1.attention.self.value': torch.Size([1000]),\n",
       " 'roberta.encoder.layer.2.attention.self.query': torch.Size([1000]),\n",
       " 'roberta.encoder.layer.2.attention.self.value': torch.Size([1000]),\n",
       " 'roberta.encoder.layer.3.attention.self.query': torch.Size([1000]),\n",
       " 'roberta.encoder.layer.3.attention.self.value': torch.Size([1000]),\n",
       " 'roberta.encoder.layer.4.attention.self.query': torch.Size([1000]),\n",
       " 'roberta.encoder.layer.4.attention.self.value': torch.Size([1000]),\n",
       " 'roberta.encoder.layer.5.attention.self.query': torch.Size([1000]),\n",
       " 'roberta.encoder.layer.5.attention.self.value': torch.Size([1000]),\n",
       " 'roberta.encoder.layer.6.attention.self.query': torch.Size([1000]),\n",
       " 'roberta.encoder.layer.6.attention.self.value': torch.Size([1000]),\n",
       " 'roberta.encoder.layer.7.attention.self.query': torch.Size([1000]),\n",
       " 'roberta.encoder.layer.7.attention.self.value': torch.Size([1000]),\n",
       " 'roberta.encoder.layer.8.attention.self.query': torch.Size([1000]),\n",
       " 'roberta.encoder.layer.8.attention.self.value': torch.Size([1000]),\n",
       " 'roberta.encoder.layer.9.attention.self.query': torch.Size([1000]),\n",
       " 'roberta.encoder.layer.9.attention.self.value': torch.Size([1000]),\n",
       " 'roberta.encoder.layer.10.attention.self.query': torch.Size([1000]),\n",
       " 'roberta.encoder.layer.10.attention.self.value': torch.Size([1000]),\n",
       " 'roberta.encoder.layer.11.attention.self.query': torch.Size([1000]),\n",
       " 'roberta.encoder.layer.11.attention.self.value': torch.Size([1000])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{key: sampled_angles[key].shape for key in sampled_angles.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming weights is the name of your dictionary\n",
    "# Can't plot 80M points. Sample 100K from distribution. Should tend to true dist.\n",
    "sampled_dist = torch.cat(list(sampled_angles.values())).numpy()\n",
    "\n",
    "plt.hist(sampled_dist, bins=100, log=True, color=\"cornflowerblue\", alpha=0.7)\n",
    "plt.title(\"Sampled Angles in Weight Matrices of 1st Split\")\n",
    "plt.xlabel(\"Angle between 2 unit vectors (Radians)\")\n",
    "plt.ylabel(\"Log Frequency\")\n",
    "\n",
    "# Draw a horizontal line at y=/2\n",
    "plt.axvline(np.pi / 2, color=\"red\", linestyle=\"dashed\", linewidth=2, label=\"x=pi/2\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
